{"cells":[{"cell_type":"markdown","id":"3d4f88b4","metadata":{"id":"3d4f88b4"},"source":["## Data loading"]},{"cell_type":"code","execution_count":null,"id":"391bee8d","metadata":{"id":"391bee8d"},"outputs":[],"source":["import sys, types, importlib\n","\n","# ---- ‚ÄúRepair shims‚Äù to alias legacy NumPy module paths to current ones ----\n","def _install_numpy_compat_shims():\n","    import numpy as np\n","    m = {}\n","\n","    # Load base modules\n","    try:\n","        np_core = importlib.import_module(\"numpy.core\")\n","        m[\"numpy.core\"] = np_core\n","    except Exception:\n","        pass\n","\n","    try:\n","        np_core_numeric = importlib.import_module(\"numpy.core.numeric\")\n","        m[\"numpy.core.numeric\"] = np_core_numeric\n","    except Exception:\n","        pass\n","\n","    try:\n","        np_core_multiarray = importlib.import_module(\"numpy.core.multiarray\")\n","        m[\"numpy.core.multiarray\"] = np_core_multiarray\n","    except Exception:\n","        np_core_multiarray = None\n","\n","    # Alias old paths -> current paths\n","    # e.g., resolve 'numpy._core.numeric' as 'numpy.core.numeric'\n","    if \"numpy.core\" in m:\n","        mod = types.ModuleType(\"numpy._core\")\n","        mod.__dict__.update(m[\"numpy.core\"].__dict__)\n","        sys.modules[\"numpy._core\"] = mod\n","\n","    if \"numpy.core.numeric\" in m:\n","        sys.modules[\"numpy._core.numeric\"] = m[\"numpy.core.numeric\"]\n","\n","    # Also handle internal modules that some old pickles may reference\n","    # (skip if unavailable)\n","    try:\n","        np_umath = importlib.import_module(\"numpy.core._multiarray_umath\")\n","        sys.modules[\"numpy._core._multiarray_umath\"] = np_umath\n","        sys.modules[\"numpy.core._multiarray_umath\"] = np_umath\n","    except Exception:\n","        # Ignore if not present in the current NumPy build/environment\n","        pass\n","\n","    # Some old pickles may reference 'numpy.core.multiarray.number'\n","    # In modern NumPy this corresponds to np.number, so we inject it as an attribute\n","    try:\n","        if np_core_multiarray is not None and not hasattr(np_core_multiarray, \"number\"):\n","            import numpy as np\n","            setattr(np_core_multiarray, \"number\", np.number)\n","    except Exception:\n","        pass\n","\n","_install_numpy_compat_shims()\n","\n","# ---- Normal loading starts here ----\n","import pickle\n","import pandas as pd\n","\n","file_path = \"/Users/path\"\n","\n","print(\"Loading the pickle file...\")\n","\n","try:\n","    # Specify encoding as a safeguard\n","    with open(file_path, \"rb\") as f:\n","        data = pickle.load(f, encoding=\"latin1\")\n","\n","    print(\"‚úÖ Loaded successfully!\")\n","    print(f\"Data type: {type(data)}\")\n","\n","    if isinstance(data, pd.DataFrame):\n","        print(f\"Shape: {data.shape}\")\n","        print(f\"Number of columns: {len(data.columns)}\")\n","        print(f\"Column names (first 20): {list(data.columns)[:20]}\")\n","        print(\"\\n--- First 5 rows ---\")\n","        print(data.head())\n","        print(\"\\n--- DataFrame info ---\")\n","        data.info()\n","    else:\n","        # If it's not a DataFrame, inspect as much as possible\n","        if hasattr(data, \"keys\"):\n","            try:\n","                print(\"Example keys:\", list(data.keys())[:10])\n","            except Exception:\n","                pass\n","        print(\"Preview:\", str(data)[:1000])\n","\n","except Exception as e:\n","    print(f\"‚ùå Error: {e}\")\n","    print(\"\\nüîß Next steps if it still fails:\")\n","    print(\"A) Retry with dill:  pip install dill  ‚Üí  import dill; dill.load(open(path,'rb'))\")\n","    print(\"B) Use a temporary venv dedicated to converting pkl ‚Üí CSV/Parquet (keeps your main env clean)\")\n"]},{"cell_type":"markdown","id":"7953281d","metadata":{"id":"7953281d"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"35ad90c5","metadata":{"id":"35ad90c5"},"outputs":[],"source":["# Reindex starting from 1\n","print(\"=\" * 50)\n","print(\"Status before reindexing\")\n","print(\"=\" * 50)\n","print(f\"Current index range: {data.index.min()} - {data.index.max()}\")\n","print(f\"Actual number of rows: {len(data)}\")\n","print(f\"Current index (first 10): {data.index[:10].tolist()}\")\n","\n","# Reset index to a consecutive sequence starting from 1\n","data_reindexed = data.reset_index(drop=True)\n","data_reindexed.index = data_reindexed.index + 1  # Adjust to start from 1\n","\n","print(\"\\n\" + \"=\" * 50)\n","print(\"Status after reindexing\")\n","print(\"=\" * 50)\n","print(f\"New index range: {data_reindexed.index.min()} - {data_reindexed.index.max()}\")\n","print(f\"Number of rows: {len(data_reindexed)}\")\n","print(f\"New index (first 10): {data_reindexed.index[:10].tolist()}\")\n","\n","# Replace the original data with the reindexed version\n","data = data_reindexed\n","print(\"‚úÖ Index has been reset to a consecutive sequence starting from 1\")\n","\n","print(\"\\n\" + \"=\" * 50)\n","print(\"Detailed missing value inspection\")\n","print(\"=\" * 50)\n","\n","# Count missing values per column\n","missing_count = data.isnull().sum()\n","missing_percentage = (data.isnull().sum() / len(data)) * 100\n","\n","# Create a DataFrame summarizing missing value information\n","missing_info = pd.DataFrame({\n","    'Column name': missing_count.index,\n","    'Missing count': missing_count.values,\n","    'Missing rate (%)': missing_percentage.values,\n","    'Data type': data.dtypes.values\n","})\n","\n","# Display only columns with missing values\n","missing_columns = missing_info[missing_info['Missing count'] > 0].sort_values(\n","    'Missing count', ascending=False\n",")\n","\n","if len(missing_columns) > 0:\n","    print(\"Columns with missing values:\")\n","    print(missing_columns.to_string(index=False))\n","\n","    print(f\"\\nNumber of columns with missing values: {len(missing_columns)}\")\n","    print(f\"Number of columns with complete data: {len(data.columns) - len(missing_columns)}\")\n","\n","    # Details for columns with a high missing rate\n","    print(f\"\\nColumns with missing rate ‚â• 50%:\")\n","    high_missing = missing_columns[missing_columns['Missing rate (%)'] >= 50]\n","    if len(high_missing) > 0:\n","        print(high_missing.to_string(index=False))\n","    else:\n","        print(\"None\")\n","\n","    # Columns that are completely missing\n","    print(f\"\\nCompletely missing columns (100% missing):\")\n","    completely_missing = missing_columns[missing_columns['Missing rate (%)'] == 100]\n","    if len(completely_missing) > 0:\n","        print(completely_missing['Column name'].tolist())\n","    else:\n","        print(\"None\")\n","\n","else:\n","    print(\"‚úÖ No missing values detected!\")\n","\n","print(f\"\\nOverall missing value statistics:\")\n","print(f\"Total number of cells: {data.shape[0] * data.shape[1]:,}\")\n","print(f\"Number of missing cells: {data.isnull().sum().sum():,}\")\n","print(\n","    f\"Overall missing rate: \"\n","    f\"{(data.isnull().sum().sum() / (data.shape[0] * data.shape[1])) * 100:.2f}%\"\n",")\n","\n","# Display basic dataset information\n","print(\"\\n\" + \"=\" * 50)\n","print(\"Basic dataset information after reindexing\")\n","print(\"=\" * 50)\n","print(f\"Data shape: {data.shape}\")\n","print(f\"Index range: {data.index.min()} to {data.index.max()}\")\n","print(\"\\nFirst 3 rows:\")\n","data.head(3)\n"]},{"cell_type":"markdown","id":"e9f4f619","metadata":{"id":"e9f4f619"},"source":["Confirm that there are some missing values.\n","\n","Year ‚á® Missing values ‚Äã‚Äãare reflected in the prompt.\n","\n","Genus, Author ‚á® Do not use for analyzing Species.\n","\n","Missing Species cannot be fixed, so delete them."]},{"cell_type":"code","execution_count":null,"id":"abc72602","metadata":{"id":"abc72602"},"outputs":[],"source":["print(\"=\" * 50)\n","print(\"Removal of rows with missing Species\")\n","print(\"=\" * 50)\n","\n","# Check dataset status before removal\n","print(\"Dataset status before removal:\")\n","print(f\"Total number of records: {len(data):,}\")\n","\n","# Check missing status of the Species column\n","if 'Species' in data.columns:\n","    species_missing = data['Species'].isnull().sum()\n","    species_valid = data['Species'].notnull().sum()\n","\n","    print(\"Status of the Species column:\")\n","    print(f\"  Valid entries: {species_valid:,}\")\n","    print(f\"  Missing entries: {species_missing:,}\")\n","    print(f\"  Missing rate: {(species_missing / len(data)) * 100:.2f}%\")\n","\n","    if species_missing > 0:\n","        print(f\"\\nNumber of rows to be removed: {species_missing:,}\")\n","\n","        # Display samples of rows with missing Species\n","        missing_species_rows = data[data['Species'].isnull()]\n","        print(\"\\nSample of rows to be removed (first 3 rows):\")\n","        print(missing_species_rows.head(3))\n","\n","        # Remove rows with missing Species\n","        data_cleaned = data[data['Species'].notnull()].copy()\n","\n","        # Reindex starting from 1\n","        data_cleaned = data_cleaned.reset_index(drop=True)\n","        data_cleaned.index = data_cleaned.index + 1\n","\n","        print(\"\\nDataset status after removal:\")\n","        print(f\"Total number of records: {len(data_cleaned):,}\")\n","        print(f\"Number of removed records: {len(data) - len(data_cleaned):,}\")\n","        print(f\"Retention rate: {(len(data_cleaned) / len(data)) * 100:.2f}%\")\n","\n","        # Verify Species column after removal\n","        print(\"\\nVerification of Species column after removal:\")\n","        print(f\"  Valid entries: {data_cleaned['Species'].notnull().sum():,}\")\n","        print(f\"  Missing entries: {data_cleaned['Species'].isnull().sum():,}\")\n","\n","        # Update the original data\n","        data = data_cleaned\n","\n","        print(\"\\n‚úÖ Removal of rows with missing Species completed\")\n","        print(f\"New index range: {data.index.min()} to {data.index.max()}\")\n","\n","        # Display sample of cleaned data\n","        print(\"\\nSample of cleaned data (first 3 rows):\")\n","        print(data.head(3))\n","\n","        # Display example values from the Species column\n","        print(\"\\nExample values from the Species column (first 10 unique values):\")\n","        unique_species = data['Species'].dropna().unique()\n","        print(unique_species[:10])\n","\n","    else:\n","        print(\"\\n‚úÖ No missing values found in the Species column\")\n","\n","else:\n","    print(\"‚ùå Error: 'Species' column does not exist\")\n","    print(f\"Available columns: {data.columns.tolist()}\")\n","\n","print(\"\\n\" + \"=\" * 50)\n","print(\"Processing completed\")\n","print(\"=\" * 50)\n"]},{"cell_type":"markdown","id":"fd2f4d1f","metadata":{"id":"fd2f4d1f"},"source":["## Label prediction with LLM"]},{"cell_type":"code","execution_count":null,"id":"dec2526b","metadata":{"id":"dec2526b"},"outputs":[],"source":["import openai\n","from openai import OpenAI\n","import pandas as pd\n","import re\n","from tqdm.auto import tqdm\n","import traceback\n","import concurrent.futures\n","import threading\n","import time\n","import random\n","import os\n","\n","# Register tqdm with pandas\n","tqdm.pandas()\n","\n","# API key list\n","api_key_list = []\n","\n","# Thread-local storage (each thread keeps its own API key / client)\n","thread_local = threading.local()\n","\n","def get_client():\n","    \"\"\"Get an OpenAI client with a per-thread rotated API key.\"\"\"\n","    if not hasattr(thread_local, \"client\"):\n","        # Select an API key based on the thread ID\n","        thread_id = threading.get_ident()\n","        key_index = thread_id % len(api_key_list)\n","        api_key = api_key_list[key_index]\n","        thread_local.client = OpenAI(api_key=api_key)\n","    return thread_local.client\n","\n","def categorize_scientific_name_six(species_name, year, max_retries=3):\n","    \"\"\"Six-category classification (3x Morphology + People (male/female) + Geography + Other).\"\"\"\n","\n","    # Handle Year: use a default if missing/invalid\n","    if pd.isna(year) or year is None or str(year).lower() in ['nan', 'none', '']:\n","        year_str = \"unknown\"\n","        year_context = \"The description year is unknown, so focus on the etymological meaning of the epithet itself.\"\n","    else:\n","        year_str = str(int(float(year))) if str(year).replace('.', '').isdigit() else str(year)\n","        year_context = f\"The species was described in {year_str}, which may influence the etymology and classification.\"\n","\n","    # ‚Äî‚Äî Minimal prompt edits only (7‚Üí6 categories, People split by male/female, Indigenous removed) ‚Äî‚Äî\n","    prompt = (\n","    \"You are an expert in taxonomic nomenclature. Scientific species epithets are derived primarily from Latin or Latinized Greek, \"\n","    \"and they often reflect morphological, ecological, geographical, cultural, or personal aspects. Please analyze the following species epithet \"\n","    \"(do not include the genus) and assign it to one or more of the following six categories:\\n\\n\"\n","    \"1. Abstract Morphology: Referring to physical appearance in general terms (e.g., small, hairy, sharp, modest).\\n\"\n","    \"2. Specific Morphology: Referring to concrete, visually verifiable traits such as color, pattern, number, or body parts (e.g., four-banded, yellow-haired, thin-legged).\\n\"\n","    \"3. Conceptual Morphology: Referring to conceptual or evaluative traits derived from morphology (e.g., unique, devil-like, different).\\n\"\n","    \"4. People: Dedicated to a person, with the final answer indicating Eponym (male) or Eponym (female). For example, 'darwini' (male) honors Charles Darwin, while 'mariae' (female) honors a woman named Maria; note that '-i' often indicates male, and '-ae' should always indicates female.\\n\"\n","    \"5. Geography: Referring to a place of origin, region, or type locality (e.g., japonicus = of Japan, tibetensis = of Tibet).\\n\"\n","    \"6. Other: If the epithet has a meaning but does not clearly fall into any of the above categories (including ecology, behavior, culture, or nonsensical names).\\n\\n\"\n","    \"Internally, perform a detailed chain-of-thought analysis explaining how you arrived at your classification. \"\n","    \"However, in your final output, provide only the final answer in the following format (do not include your internal reasoning):\\n\\n\"\n","    \"Format: Abstract_Morphology: [Yes/None], Specific_Morphology: [Yes/None], Conceptual_Morphology: [Yes/None], \"\n","    \"People: [Eponym (male)/Eponym (female)/None], Geography: [Yes/None], Other: [Yes/None]\\n\\n\"\n","    \"The species was described in the year, which may influence whether it references an older historical figure, a more modern cultural reference, \"\n","    \"or a classical Latin/Greek etymology. Consider this date in your classification.\\n\\n\"\n","    \"Few-shot examples:\\n\\n\"\n","    \"Example 1:\\n\"\n","    \"Species epithet: \\\"pusillus\\\"\\n\"\n","    \"Year: 1847\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'pusillus' is Latin for 'very small', which clearly refers to a general size-related characteristic. \"\n","    \"This is a morphological descriptor of an abstract type (size) rather than a specific or conceptual trait. \"\n","    \"It is not related to geography, people, or other categories.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: Yes, Specific_Morphology: None, Conceptual_Morphology: None, People: None, Geography: None, Other: None\\n\\n\"\n","    \"Example 2:\\n\"\n","    \"Species epithet: \\\"flavopilosus\\\"\\n\"\n","    \"Year: 1901\\n\"\n","    \"Chain-of-Thought: \\\"The epithet combines 'flavo-' (yellow) and 'pilosus' (hairy), referring directly to a visible color and body hair trait. \"\n","    \"This is a clear example of specific, visually verifiable morphology. \"\n","    \"It does not involve abstract description, conceptual imagery, geography, or dedication to a person.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: Yes, Conceptual_Morphology: None, People: None, Geography: None, Other: None\\n\\n\"\n","    \"Example 3:\\n\"\n","    \"Species epithet: \\\"unica\\\"\\n\"\n","    \"Year: 1923\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'unica' means 'unique' in Latin. This does not describe a direct visual feature but rather conveys a conceptual evaluation \"\n","    \"about the organism's distinctiveness. Thus, it falls into conceptual morphology. \"\n","    \"There is no geographical, personal, or cultural association.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: None, Conceptual_Morphology: Yes, People: None, Geography: None, Other: None\\n\\n\"\n","    \"Example 4:\\n\"\n","    \"Species epithet: \\\"darwini\\\"\\n\"\n","    \"Year: 1845\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'darwini' is formed in the genitive case, honoring Charles Darwin. The '-i' ending indicates a male eponym. \"\n","    \"This is a personal dedication, not related to morphology, geography, or cultural references.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: None, Conceptual_Morphology: None, People: Eponym (male), Geography: None, Other: None\\n\\n\"\n","    \"Example 5:\\n\"\n","    \"Species epithet: \\\"mariae\\\"\\n\"\n","    \"Year: 1903\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'mariae' is also in the genitive case, dedicated to a woman named Maria. The '-ae' ending is a strong indicator that the honoree is female. \"\n","    \"Therefore, this is classified as a female eponym.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: None, Conceptual_Morphology: None, People: Eponym (female), Geography: None, Other: None\\n\\n\"\n","    \"Example 6:\\n\"\n","    \"Species epithet: \\\"formosensis\\\"\\n\"\n","    \"Year: 1935\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'formosensis' refers to Formosa (Taiwan). The suffix '-ensis' is a standard indicator of geographic origin. \"\n","    \"It is not morphological, personal, or cultural, but clearly geographical.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: None, Conceptual_Morphology: None, People: None, Geography: Yes, Other: None\\n\\n\"\n","    \"Example 7:\\n\"\n","    \"Species epithet: \\\"nocturnus\\\"\\n\"\n","    \"Year: 1901\\n\"\n","    \"Chain-of-Thought: \\\"The epithet 'nocturnus' means 'active at night', describing the behavior or ecological niche of the species. \"\n","    \"It does not correspond to morphology, geography, or people, but instead represents an ecological/behavioral trait. \"\n","    \"Thus, it falls under 'Other'.\\\"\\n\"\n","    \"Final Answer: Abstract_Morphology: None, Specific_Morphology: None, Conceptual_Morphology: None, People: None, Geography: None, Other: Yes\\n\\n\"\n","    \"Now, please analyze the following species epithet and output only the final answer.\\n\"\n","    f\"Species epithet: {species_name}\\n\"\n","    f\"Year: {year}\\n\\n\"\n","    \"Final Answer:\"\n",")\n","    # ‚Äî‚Äî End of prompt edits ‚Äî‚Äî\n","\n","    client = get_client()\n","\n","    for attempt in range(max_retries):\n","        try:\n","            response = client.chat.completions.create(\n","                model=\"gpt-4.1-mini-2025-04-14\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                max_tokens=150,\n","                temperature=0\n","            )\n","            result = response.choices[0].message.content.strip()\n","            return result\n","        except Exception as e:\n","            if attempt < max_retries - 1:\n","                # Wait briefly on rate limits\n","                wait_time = (2 ** attempt) + random.uniform(0, 1)\n","                time.sleep(wait_time)\n","                continue\n","            else:\n","                return f\"Error after {max_retries} attempts: {e}\"\n","\n","    return \"Error: Max retries exceeded\"\n","\n","def parse_llm_result_six(llm_str):\n","    \"\"\"Parse the LLM output into six categories (People is split into male/female).\"\"\"\n","    categories = {\n","        \"Abstract_Morphology\": 0,\n","        \"Specific_Morphology\": 0,\n","        \"Conceptual_Morphology\": 0,\n","        \"People_Male\": 0,\n","        \"People_Female\": 0,\n","        \"Geography\": 0,\n","        \"Other\": 0\n","    }\n","    try:\n","        parts = [p.strip() for p in str(llm_str).split(\",\")]\n","        for part in parts:\n","            if \":\" in part:\n","                key, value = part.split(\":\", 1)\n","                key = key.strip()\n","                value_norm = value.strip().lower()\n","                # Morphology / Geography / Other: Yes/None\n","                if key in [\"Abstract_Morphology\", \"Specific_Morphology\", \"Conceptual_Morphology\", \"Geography\", \"Other\"]:\n","                    if value_norm != \"none\":\n","                        categories[key] = 1\n","                # People requires special handling\n","                elif key == \"People\":\n","                    if \"male\" in value_norm:\n","                        categories[\"People_Male\"] = 1\n","                    elif \"female\" in value_norm:\n","                        categories[\"People_Female\"] = 1\n","        return categories\n","    except Exception:\n","        return categories\n","\n","def process_single_item(args):\n","    \"\"\"Process a single item (for parallel execution).\"\"\"\n","    idx, species_name, year = args\n","    try:\n","        result = categorize_scientific_name_six(species_name, year)\n","        return idx, result\n","    except Exception as e:\n","        return idx, f\"Error: {e}\"\n","\n","def process_batch_parallel(batch_data, batch_id, max_workers=15):\n","    \"\"\"Process a batch in parallel.\"\"\"\n","    print(f\"Starting batch {batch_id} ({len(batch_data)} records)\")\n","\n","    # Prepare inputs\n","    process_args = [(idx, row['Species'], row['Year']) for idx, row in batch_data.iterrows()]\n","\n","    results = {}\n","\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n","        # Submit each row for parallel processing\n","        future_to_idx = {\n","            executor.submit(process_single_item, args): args[0]\n","            for args in process_args\n","        }\n","\n","        # Collect results\n","        for future in tqdm(\n","            concurrent.futures.as_completed(future_to_idx),\n","            total=len(future_to_idx),\n","            desc=f\"Batch {batch_id}\"\n","        ):\n","            try:\n","                idx, result = future.result(timeout=120)  # Timeout after 120 seconds\n","                results[idx] = result\n","            except Exception as e:\n","                idx = future_to_idx[future]\n","                print(f\"Error occurred (idx {idx}): {e}\")\n","                results[idx] = f\"Error: {e}\"\n","\n","    # Restore original order\n","    ordered_results = [results[idx] for idx in batch_data.index]\n","\n","    print(f\"Finished batch {batch_id}\")\n","    return ordered_results\n","\n","def main_processing():\n","    \"\"\"Main processing function (six-category version).\"\"\"\n","    print(\"=\" * 60)\n","    print(\"Starting six-category LLM classification for Animalia scientific epithets\")\n","    print(\"=\" * 60)\n","\n","    # Data summary\n","    print(f\"Total records to process: {len(data):,}\")\n","\n","    # Validate required columns\n","    if 'Species' not in data.columns:\n","        print(\"‚ùå Error: 'Species' column not found\")\n","        print(f\"Available columns: {data.columns.tolist()}\")\n","        return\n","\n","    if 'Year' not in data.columns:\n","        print(\"‚ùå Error: 'Year' column not found\")\n","        print(f\"Available columns: {data.columns.tolist()}\")\n","        return\n","\n","    # Batch settings\n","    batch_size = 3000  # Process in chunks of 3000\n","    max_workers = 25   # Parallel workers\n","    total_batches = (len(data) + batch_size - 1) // batch_size\n","\n","    print(f\"Batch size: {batch_size}\")\n","    print(f\"Total batches: {total_batches}\")\n","    print(f\"Parallel workers: {max_workers}\")\n","\n","    # Create output directory\n","    save_dir = \"/Users/path\"\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Store all outputs\n","    all_results = []\n","\n","    # Process batches\n","    for i in tqdm(range(0, len(data), batch_size), desc=\"Overall progress\"):\n","        batch_data = data.iloc[i:i+batch_size]\n","        batch_id = i // batch_size + 1\n","\n","        print(f\"\\n{'='*40}\")\n","        print(f\"Starting batch {batch_id}/{total_batches}\")\n","        print(f\"Range: {i:,} - {min(i+batch_size-1, len(data)-1):,}\")\n","        print(f\"{'='*40}\")\n","\n","        # Run parallel batch processing\n","        batch_results = process_batch_parallel(batch_data, batch_id, max_workers)\n","        all_results.extend(batch_results)\n","\n","        # Show the last inference result in the batch (roughly every 1000+ entries depending on batch)\n","        if len(batch_results) > 0:\n","            last_idx = i + len(batch_results) - 1\n","            last_species = batch_data.iloc[-1]['Species']\n","            last_year = batch_data.iloc[-1]['Year']\n","            last_result = batch_results[-1]\n","\n","            print(f\"\\nüìù Inference result at record {len(all_results)}:\")\n","            print(f\"   Species: {last_species}\")\n","            print(f\"   Year:    {last_year}\")\n","            print(f\"   Output:  {last_result}\")\n","\n","            # Parse and display categories (six-category aware)\n","            if 'Error' not in str(last_result):\n","                parsed = parse_llm_result_six(last_result)\n","                categories = []\n","                if parsed[\"Abstract_Morphology\"]:\n","                    categories.append('Abstract morphology')\n","                if parsed[\"Specific_Morphology\"]:\n","                    categories.append('Specific morphology')\n","                if parsed[\"Conceptual_Morphology\"]:\n","                    categories.append('Conceptual morphology')\n","                if parsed[\"People_Male\"]:\n","                    categories.append('People (male)')\n","                if parsed[\"People_Female\"]:\n","                    categories.append('People (female)')\n","                if parsed[\"Geography\"]:\n","                    categories.append('Geography')\n","                if parsed[\"Other\"]:\n","                    categories.append('Other')\n","\n","                cat_str = ', '.join(categories) if categories else 'No category'\n","                print(f\"   Categories: {cat_str}\")\n","\n","        # Interim save\n","        print(f\"\\nüìä Interim save: processed {len(all_results):,} records\")\n","\n","        temp_data = data.iloc[:len(all_results)].copy()\n","        temp_data['LLM_Scientific_Categories_Final6'] = all_results\n","\n","        interim_path = os.path.join(save_dir, f\"LLM_interim_6cat_{len(all_results):07d}.csv\")\n","        temp_data.to_csv(interim_path, index=False)\n","        print(f\"üíæ Saved interim file: {interim_path}\")\n","\n","        # Rate-limit mitigation\n","        if batch_id < total_batches:\n","            print(\"‚è≥ Waiting briefly to mitigate rate limits...\")\n","            time.sleep(2)\n","\n","    print(f\"\\nüéâ Completed all records: {len(all_results):,}\")\n","\n","    # Write final outputs\n","    data['LLM_Scientific_Categories_Final6'] = all_results\n","\n","    # Create category flags (six-category aware)\n","    print(\"üè∑Ô∏è  Creating category flags...\")\n","\n","    tqdm.pandas(desc=\"Abstract_Morphology\")\n","    data[\"LLM_Scientific_Abstract_Morphology\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"Abstract_Morphology\"]\n","    )\n","\n","    tqdm.pandas(desc=\"Specific_Morphology\")\n","    data[\"LLM_Scientific_Specific_Morphology\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"Specific_Morphology\"]\n","    )\n","\n","    tqdm.pandas(desc=\"Conceptual_Morphology\")\n","    data[\"LLM_Scientific_Conceptual_Morphology\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"Conceptual_Morphology\"]\n","    )\n","\n","    tqdm.pandas(desc=\"People_Male\")\n","    data[\"LLM_Scientific_People_Male\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"People_Male\"]\n","    )\n","\n","    tqdm.pandas(desc=\"People_Female\")\n","    data[\"LLM_Scientific_People_Female\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"People_Female\"]\n","    )\n","\n","    tqdm.pandas(desc=\"Geography\")\n","    data[\"LLM_Scientific_Geography\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"Geography\"]\n","    )\n","\n","    tqdm.pandas(desc=\"Other\")\n","    data[\"LLM_Scientific_Other\"] = data[\"LLM_Scientific_Categories_Final6\"].progress_apply(\n","        lambda x: parse_llm_result_six(x)[\"Other\"]\n","    )\n","\n","    # Save final results\n","    final_path = os.path.join(save_dir, \"animalia_LLM_classified_final_6categories.csv\")\n","    data.to_csv(final_path, index=False)\n","\n","    print(f\"\\nüíæ Saved final results: {final_path}\")\n","\n","    # Summary (six-category aware)\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"üìà Summary\")\n","    print(\"=\" * 60)\n","\n","    result_columns = [\n","        'Species', 'Year', 'LLM_Scientific_Categories_Final6',\n","        'LLM_Scientific_Abstract_Morphology', 'LLM_Scientific_Specific_Morphology',\n","        'LLM_Scientific_Conceptual_Morphology', 'LLM_Scientific_People_Male',\n","        'LLM_Scientific_People_Female', 'LLM_Scientific_Geography', 'LLM_Scientific_Other'\n","    ]\n","\n","    print(\"\\nüìã First 10 results:\")\n","    print(data[result_columns].head(10))\n","\n","    print(\"\\nüìä Category statistics:\")\n","    total_count = len(data)\n","    print(f\"Abstract Morphology:    {data['LLM_Scientific_Abstract_Morphology'].sum():,} ({data['LLM_Scientific_Abstract_Morphology'].mean()*100:.1f}%)\")\n","    print(f\"Specific Morphology:    {data['LLM_Scientific_Specific_Morphology'].sum():,} ({data['LLM_Scientific_Specific_Morphology'].mean()*100:.1f}%)\")\n","    print(f\"Conceptual Morphology:  {data['LLM_Scientific_Conceptual_Morphology'].sum():,} ({data['LLM_Scientific_Conceptual_Morphology'].mean()*100:.1f}%)\")\n","    print(f\"People (Male):          {data['LLM_Scientific_People_Male'].sum():,} ({data['LLM_Scientific_People_Male'].mean()*100:.1f}%)\")\n","    print(f\"People (Female):        {data['LLM_Scientific_People_Female'].sum():,} ({data['LLM_Scientific_People_Female'].mean()*100:.1f}%)\")\n","    print(f\"Geography:              {data['LLM_Scientific_Geography'].sum():,} ({data['LLM_Scientific_Geography'].mean()*100:.1f}%)\")\n","    print(f\"Other:                  {data['LLM_Scientific_Other'].sum():,} ({data['LLM_Scientific_Other'].mean()*100:.1f}%)\")\n","\n","    # Error count\n","    error_count = data['LLM_Scientific_Categories_Final6'].str.contains('Error', na=False).sum()\n","    print(f\"\\n‚ùå Errors: {error_count:,} ({error_count/total_count*100:.2f}%)\")\n","\n","    print(\"\\n‚úÖ All done!\")\n","\n","    return data\n","\n","# Convenience runner\n","def run_classification():\n","    \"\"\"Run the classification pipeline (six-category version).\"\"\"\n","    print(\"üöÄ Starting LLM-based scientific epithet classification for Animalia...\")\n","    print(f\"üìä Total records: {len(data):,}\")\n","    print(\"üìù The last inference result will be printed periodically.\")\n","    print(\"üìä Six categories: Abstract morphology, Specific morphology, Conceptual morphology, People (male/female), Geography, Other\")\n","\n","    # Confirmation\n","    response = input(\"Start processing? (y/n): \")\n","    if response.lower() != 'y':\n","        print(\"Cancelled.\")\n","        return\n","\n","    # Run\n","    result_data = main_processing()\n","    return result_data\n","\n","print(\"\\nüîß Ready!\")\n","print(\"To run: call run_classification()\")\n","print(f\"Target: {len(data):,} records\")\n","print(\"üìä Six categories: Abstract morphology, Specific morphology, Conceptual morphology, People (male/female), Geography, Other\")\n"]},{"cell_type":"code","execution_count":null,"id":"4d96ab7a","metadata":{"id":"4d96ab7a"},"outputs":[],"source":["# Start processing\n","run_classification()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}