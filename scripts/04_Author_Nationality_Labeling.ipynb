{"cells":[{"cell_type":"code","execution_count":null,"id":"81cf38c2","metadata":{"id":"81cf38c2"},"outputs":[],"source":["# Load Parquet file\n","import pandas as pd\n","\n","# Path to the Parquet file\n","path = \"/Users/path\"\n","\n","# Read the Parquet file\n","df = pd.read_parquet(path)\n"]},{"cell_type":"code","execution_count":null,"id":"90417c41","metadata":{"id":"90417c41"},"outputs":[],"source":["import openai\n","from openai import OpenAI\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import concurrent.futures\n","import threading\n","import time\n","import random\n","import os\n","\n","# Register tqdm with pandas\n","tqdm.pandas()\n","\n","# ====== Put your API keys here ======\n","api_key_list = []\n","# ===================================\n","\n","# Thread-local storage (each thread keeps its own API key / client)\n","thread_local = threading.local()\n","\n","def get_client():\n","    \"\"\"Get an OpenAI client with a per-thread rotated API key.\"\"\"\n","    if not hasattr(thread_local, \"client\"):\n","        thread_id = threading.get_ident()\n","        api_key = api_key_list[thread_id % len(api_key_list)]\n","        thread_local.client = OpenAI(api_key=api_key)\n","    return thread_local.client\n","\n","\n","# ===================== â‘  LLM call =====================\n","\n","def classify_author_region_country(author_str, year=None, max_retries=3):\n","    \"\"\"\n","    Infer (Region, Country) from an author string and an optional publication year.\n","\n","    The LLM output MUST be exactly one line:\n","      Region: <region>, Country: <country>\n","    \"\"\"\n","\n","    # Skip if Author is missing\n","    if pd.isna(author_str) or str(author_str).strip() == \"\":\n","        return \"Skipped: Author missing\"\n","\n","    author_str = str(author_str).strip()\n","\n","    # Handle Year\n","    if year is None or pd.isna(year) or str(year).strip() == \"\":\n","        year_str_for_prompt = \"unknown\"\n","        year_info_text = (\n","            \"The publication year is unknown. Ignore year information and rely solely on \"\n","            \"surname origin and typical geographic usage.\"\n","        )\n","    else:\n","        try:\n","            year_int = int(float(year))\n","            year_str_for_prompt = str(year_int)\n","        except Exception:\n","            year_str_for_prompt = str(year).strip()\n","\n","        year_info_text = (\n","            f\"The publication year is {year_str_for_prompt}. \"\n","            \"This can be used as a very weak hint only, but the surname origin must remain \"\n","            \"the primary basis for determining region/country.\"\n","        )\n","\n","    # ==== Prompt (force single-line output) ====\n","    prompt = f\"\"\"\n","You are an expert in global surname origins and geography.\n","Given an author string and a publication year, infer the most likely macro-region and modern country\n","of the FIRST author.\n","\n","Follow these rules strictly:\n","1. Classify primarily based on the origin and typical geographic distribution of the first surname.\n","2. Use the publication year only as a very weak secondary hint.\n","3. If the year is unknown, ignore it.\n","4. If the classification is genuinely uncertain, output 'Unknown'.\n","5. Region must be exactly one of:\n","   Europe / Middle East / Asia / Africa / North America / Latin America / Unknown\n","6. Country must be a modern country name in English. If uncertain â†’ 'Unknown'.\n","\n","IMPORTANT OUTPUT CONSTRAINTS:\n","- You MUST output exactly ONE line.\n","- The line MUST start with 'Region:'.\n","- The line MUST contain a comma after the region part.\n","- You MUST NOT output any explanations, analysis, or reasoning.\n","- DO NOT output words like 'because', 'Chain-of-thought', or any justification.\n","\n","Output format (MUST follow this exactly):\n","Region: <one of the 6 regions or Unknown>, Country: <country name or Unknown>\n","\n","Examples (OUTPUT FORMAT ONLY):\n","\n","Example 1\n","Input:\n","  Author string: \"MÃ¼ller and Zimmer, 1936\"\n","  Publication year: 1936\n","Output:\n","  Region: Europe, Country: Germany\n","\n","Example 2\n","Input:\n","  Author string: \"Nguyen, 1995\"\n","  Publication year: 1995\n","Output:\n","  Region: Asia, Country: Vietnam\n","\n","Now classify the following record.\n","\n","Author string: \"{author_str}\"\n","Publication year: {year_str_for_prompt}\n","\n","{year_info_text}\n","\n","Remember: output ONLY one line in this format:\n","Region: <region>, Country: <country>\n","\"\"\"\n","\n","    client = get_client()\n","\n","    for attempt in range(max_retries):\n","        try:\n","            response = client.chat.completions.create(\n","                model=\"gpt-4.1-mini\",\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                max_tokens=20,  # Keep small to encourage a single-line output\n","                temperature=0\n","            )\n","            return response.choices[0].message.content.strip()\n","\n","        except Exception as e:\n","            if attempt < max_retries - 1:\n","                # Retry on failures such as rate limits\n","                wait = (2 ** attempt) + random.uniform(0, 1)\n","                time.sleep(wait)\n","            else:\n","                return f\"Error after {max_retries} attempts: {e}\"\n","\n","    return \"Error: Max retries exceeded\"\n","\n","\n","# ===================== â‘¡ Parsing =====================\n","\n","def parse_region_country(llm_str):\n","    \"\"\"\n","    Parse the LLM output string, e.g.:\n","      'Region: Europe, Country: Germany'\n","    into a dict.\n","    \"\"\"\n","    result = {\"Region\": \"Unknown\", \"Country\": \"Unknown\"}\n","\n","    if not isinstance(llm_str, str):\n","        return result\n","    if \"Skipped\" in llm_str or \"Error\" in llm_str:\n","        return result\n","\n","    try:\n","        parts = [p.strip() for p in llm_str.split(\",\")]\n","        for part in parts:\n","            if \":\" not in part:\n","                continue\n","            key, value = part.split(\":\", 1)\n","            key = key.strip().lower()\n","            value = value.strip()\n","            if key == \"region\":\n","                result[\"Region\"] = value\n","            elif key == \"country\":\n","                result[\"Country\"] = value\n","    except Exception:\n","        pass\n","\n","    return result\n","\n","\n","# ===================== â‘¢ Parallel processing =====================\n","\n","def process_single_item(args):\n","    \"\"\"Process a single row (for parallel execution).\"\"\"\n","    idx, author_str, year = args\n","\n","    if pd.isna(author_str) or str(author_str).strip() == \"\":\n","        return idx, \"Skipped: Author missing\"\n","\n","    try:\n","        result = classify_author_region_country(author_str, year)\n","        return idx, result\n","    except Exception as e:\n","        return idx, f\"Error: {e}\"\n","\n","\n","def process_batch_parallel(batch_data, batch_id, max_workers=15):\n","    \"\"\"Process one batch in parallel.\"\"\"\n","    print(f\"\\nStarting batch {batch_id} ({len(batch_data)} records)\")\n","\n","    # Target Author / Year columns in df\n","    process_args = [\n","        (idx, row[\"Author\"], row[\"Year\"])\n","        for idx, row in batch_data.iterrows()\n","    ]\n","\n","    results = {}\n","\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n","        future_to_idx = {\n","            executor.submit(process_single_item, args): args[0]\n","            for args in process_args\n","        }\n","\n","        for future in tqdm(\n","            concurrent.futures.as_completed(future_to_idx),\n","            total=len(future_to_idx),\n","            desc=f\"Batch {batch_id}\"\n","        ):\n","            idx = future_to_idx[future]\n","            try:\n","                _, result = future.result()\n","                results[idx] = result\n","            except Exception as e:\n","                print(f\"Error occurred (idx {idx}): {e}\")\n","                results[idx] = f\"Error: {e}\"\n","\n","    ordered_results = [results[idx] for idx in batch_data.index]\n","    print(f\"Finished batch {batch_id}\")\n","    return ordered_results\n","\n","\n","# ===================== â‘£ Main processing =====================\n","\n","def main_processing():\n","    \"\"\"\n","    Main pipeline:\n","    Assign (Region, Country) to df based on Author / Year columns.\n","    \"\"\"\n","    global df  # Assume df exists globally\n","\n","    print(\"=\" * 60)\n","    print(\"Starting LLM-based author region/country classification\")\n","    print(\"=\" * 60)\n","\n","    print(f\"Total records: {len(df):,}\")\n","\n","    # Validate required columns\n","    missing_cols = [c for c in [\"Author\", \"Year\"] if c not in df.columns]\n","    if missing_cols:\n","        print(f\"âŒ Error: Missing required columns: {missing_cols}\")\n","        print(f\"Available columns: {df.columns.tolist()}\")\n","        return\n","\n","    # Batch settings\n","    batch_size = 3000\n","    max_workers = 25\n","    total_batches = (len(df) + batch_size - 1) // batch_size\n","\n","    print(f\"Batch size: {batch_size}\")\n","    print(f\"Total batches: {total_batches}\")\n","    print(f\"Parallel workers: {max_workers}\")\n","\n","    # Output directory\n","    save_dir = \"/User/path\"\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    all_results = []\n","\n","    # Batch progress with tqdm\n","    for i in tqdm(range(0, len(df), batch_size), desc=\"All batches\"):\n","        batch_data = df.iloc[i:i + batch_size]\n","        batch_id = i // batch_size + 1\n","\n","        batch_results = process_batch_parallel(batch_data, batch_id, max_workers)\n","        all_results.extend(batch_results)\n","\n","        # Interim save\n","        temp_data = df.iloc[:len(all_results)].copy()\n","        temp_data[\"LLM_Author_RegionCountry_raw\"] = all_results\n","        temp_data[\"LLM_Author_Region\"] = temp_data[\"LLM_Author_RegionCountry_raw\"].apply(\n","            lambda x: parse_region_country(x)[\"Region\"]\n","        )\n","        temp_data[\"LLM_Author_Country\"] = temp_data[\"LLM_Author_RegionCountry_raw\"].apply(\n","            lambda x: parse_region_country(x)[\"Country\"]\n","        )\n","\n","        interim_path = os.path.join(\n","            save_dir, f\"LLM_author_region_country_interim_{len(all_results):07d}.csv\"\n","        )\n","        temp_data.to_csv(interim_path, index=False)\n","        print(f\"ðŸ’¾ Saved interim file: {interim_path}\")\n","\n","    print(f\"\\nðŸŽ‰ Completed all records: {len(all_results):,}\")\n","\n","    # Write final results back to df\n","    df[\"LLM_Author_RegionCountry_raw\"] = all_results\n","    df[\"LLM_Author_Region\"] = df[\"LLM_Author_RegionCountry_raw\"].apply(\n","        lambda x: parse_region_country(x)[\"Region\"]\n","    )\n","    df[\"LLM_Author_Country\"] = df[\"LLM_Author_RegionCountry_raw\"].apply(\n","        lambda x: parse_region_country(x)[\"Country\"]\n","    )\n","\n","    # Final save\n","    final_path = os.path.join(\n","        save_dir, \"author_region_country_LLM_classified_final.csv\"\n","    )\n","    df.to_csv(final_path, index=False)\n","    print(f\"\\nðŸ’¾ Saved final results: {final_path}\")\n","\n","    # Summary\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"ðŸ“ˆ Summary\")\n","    print(\"=\" * 60)\n","\n","    print(\"\\nðŸ“‹ First 10 results:\")\n","    print(\n","        df[\n","            [\n","                \"Author\",\n","                \"Year\",\n","                \"LLM_Author_RegionCountry_raw\",\n","                \"LLM_Author_Region\",\n","                \"LLM_Author_Country\",\n","            ]\n","        ].head(10)\n","    )\n","\n","    print(\"\\nðŸ“Š Counts by Region:\")\n","    print(df[\"LLM_Author_Region\"].value_counts(dropna=False))\n","\n","    print(\"\\nðŸ“Š Top 20 Countries:\")\n","    print(df[\"LLM_Author_Country\"].value_counts(dropna=False).head(20))\n","\n","    # Error count\n","    error_count = (\n","        df[\"LLM_Author_RegionCountry_raw\"]\n","        .astype(str)\n","        .str.contains(\"Error\", na=False)\n","        .sum()\n","    )\n","    total_count = len(df)\n","    print(f\"\\nâŒ Errors: {error_count:,} ({error_count/total_count*100:.2f}%)\")\n","\n","    print(\"\\nâœ… Done!\")\n","    return df\n","\n","\n","# ===================== â‘¤ Quick preview (first row) =====================\n","\n","def preview_first_one(df):\n","    \"\"\"\n","    Classify only the first record with the LLM and print the result immediately.\n","    \"\"\"\n","    print(\"\\n===============================\")\n","    print(\"ðŸ” Preview: First 1 LLM Result\")\n","    print(\"===============================\\n\")\n","\n","    if len(df) == 0:\n","        print(\"The dataset is empty.\")\n","        return\n","\n","    row = df.iloc[0]\n","    author = row[\"Author\"]\n","    year = row[\"Year\"]\n","\n","    if pd.isna(author) or str(author).strip() == \"\":\n","        raw = \"Skipped: Author missing\"\n","    else:\n","        raw = classify_author_region_country(author, year)\n","\n","    parsed = parse_region_country(raw)\n","\n","    print(f\"[0] Author: {author}\")\n","    print(f\"    Year:   {year}\")\n","    print(f\"    Raw:    {raw}\")\n","    print(f\"    â†’ Region: {parsed['Region']}, Country: {parsed['Country']}\\n\")\n","\n","    print(\"===============================================\")\n","    print(\"Preview finished. Starting full processing with tqdm.\")\n","    print(\"===============================================\\n\")\n","\n","\n","# ===================== â‘¥ Runner wrapper =====================\n","\n","def run_classification():\n","    \"\"\"\n","    Runner wrapper:\n","    - Show an immediate preview for the first record\n","    - Then run full processing with tqdm\n","    \"\"\"\n","    global df\n","    print(\"ðŸš€ Starting LLM-based author region/country classification...\")\n","    print(f\"ðŸ“Š Total records: {len(df):,}\")\n","    print(\"ðŸ“Œ Rows with missing Author will be skipped (Region/Country remain Unknown).\")\n","    print(\"ðŸ“Œ Rows with missing Year will be inferred using Author only.\")\n","\n","    # Quick preview for the first record\n","    preview_first_one(df)\n","\n","    response = input(\"Start processing the full dataset? (y/n): \")\n","    if response.lower() != \"y\":\n","        print(\"Cancelled.\")\n","        return\n","\n","    result_data = main_processing()\n","    return result_data\n","\n","\n","print(\"\\nðŸ”§ Ready!\")\n","print(\"Prepare df first, then call run_classification().\")\n","print(\"Example:\")\n","print(\"  df = pd.read_csv('your_input.csv')\")\n","print(\"  run_classification()\")\n"]},{"cell_type":"code","execution_count":null,"id":"e62dcc24","metadata":{"id":"e62dcc24"},"outputs":[],"source":["# ===================== Execution =====================\n","\n","if __name__ == \"__main__\":\n","\n","    # Run classification\n","    result_df = run_classification()\n","\n","    # Display results after completion (optional)\n","    print(\"\\n=== Top 5 rows of LLM inference results ===\")\n","    print(result_df.head(5))\n","\n","    print(\"\\nðŸŽ‰ All processing completed successfully!\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}